install.packages("dplyr")
install.packages("rJava")
install.packages("KoNLP")
install.packages("tm")
install.packages("RColorBrewer")
install.packages("stringr")
install.packages("wordcloud")
library(dplyr) # 편집 함수
library(rJava) # 한글 텍스트마이닝 라이브러리인 KoNLP을 실행하기 위해 필요
library(KoNLP) # 한글 문자열  처리를 위한 라이브러리
library(tm)  # 영문 문자열  처리를 위한 라이브러리
library(RColorBrewer)  # 워드클라우드 색상 지정용 라이브러리
library(stringr)  #문자열 처리를 위한 라이브러리
library(wordcloud)
useSejongDic()
library(dplyr) # 편집 함수
library(rJava) # 한글 텍스트마이닝 라이브러리인 KoNLP을 실행하기 위해 필요
library(KoNLP) # 한글 문자열  처리를 위한 라이브러리
library(tm)  # 영문 문자열  처리를 위한 라이브러리
library(RColorBrewer)  # 워드클라우드 색상 지정용 라이브러리
library(stringr)  #문자열 처리를 위한 라이브러리
library(wordcloud)  # 워드클라우드(텍스트 마이닝 시각화) 라이브러리
useSejongDic()
#'아버지가 방에 스르륵 들어가신다.' 분석
sentence<-'아버지가 방에 스르륵 들어가신다.'
extractNoun(sentence) #명사 추출함수
?extractNoun
#스스륵은 명사가 아니라 부사, 세종 사전에 스르륵이란 단어가 포함되어 있지 않음
#따라서, mergeUserDic이라는 사전에 단어를 추가하는 함수 사용
#앞부분에는 내가 사전에 추가하고자 하는 단어, 뒤에는 해당 단어의 품사를 선언
#품사의 종류는 KAIST 품사 태그셋 참조 스르륵은 일반부사임으로 mag 태그를 달아주었음
mergeUserDic(data.frame(c('스르륵'),c('mag')))
extractNoun(sentence) #스르륵이 없어짐
#이제 'MorphAnalyzer'이라는 형태소 분석 함수 이용
MorphAnalyzer(sentence)
#1. 데이터 불러오기(예전 멜론 1위~50위 노래 가사집 참조)
setwd("C:/Users/Chankoo/Desktop/180531_텍스트전처리")
temp1<-file("hiphop.txt",encoding = "UTF-8")
txt <- readLines(temp1)
#readLines는 파일을 행단위로 읽어 벡터로 저장해주는 역할을 함
head(txt)
#2. 불용어 처리-특수문자 제거하기(밑에서 더 자세서하게 다룰 예정)
#-stringr패키지의 str_replace_all()을 이용해서 문장에 들어있는 특수문자를 빈값으로 수정
txt <- str_replace_all(txt, "\\W", " ")
#3. 가장 많이 사용되는 단어 추출
#가사에서 명사 추출
nouns <- extractNoun(txt) #extractNoun함수는 결과를 리스트형태로 반환
nouns
temp1<-file("hiphop.txt",encoding = "UTF-8")
txt <- readLines(temp1)
temp1
#1. 데이터 불러오기
#영화 박열의 네이버 리뷰를 크롤링해 .txt 파일로 저장한 것을 사용
data <- readLines("review.txt")
head(data)#수
#2. 명사 추출
#extractNoun으로 명사를 추출
#sapply() 함수를 사용할 건데 function에 extractNoun을 넣으면 된다.
#리뷰 텍스트파일인 만큼 컬럼은 필요없으니 USE.NAMES=F 라는 옵션으로 컬럼명을 뺀다.
data <- sapply(data, extractNoun, USE.NAMES = F)
#sapply는 리스트형태로 리턴
#분석을 위해 unlist()를 이용해 다시 벡터로 변환
data_unlist <- unlist(data)
head(data)
#빈도수를 출력하기 위해 table 함수 사용
wordcount <- table(data_unlist)
head(wordcount)
#head()를 이용해 최대빈도 100개 정도면 뽑아 다른 변수에 넣음
wordcount_top <-head(sort(wordcount, decreasing = T),100)
wordcount_top
#3. 전처리 제 1과정: 등록
#이제 전처리가 필요
#영화리뷰는 신조어 등으로 제대로 된 데이터를 뽑기가 힘들다.
#사전에 없는 단어들이고, 그것마저 사람마다 여러 형태로 변형해서 쓰며
#띄어쓰기는 고사하고 오타마저 너무나 빈번
#앞에 나온 mergeUserDic() 을 사용해 우리가 수동으로 단어들을 등록 ex) '꿀잼', '노답'
mergeUserDic(data.frame(c("노잼"), "ncn")) #ncn은 형태소 분석상 명사라는 뜻
#한꺼번에 등록하기 위에 메모장으로 단어집을 만들고 등록하는 방법도 있음
mergeUserDic(data.frame(readLines("addNoun.txt"), "ncn"))
#등록 후 위에 과정 다시 수행
data <- sapply(data, extractNoun, USE.NAMES = F)
data_unlist <- unlist(data)
#4. 전처리 제 2과정: filter(2글자 이상의 단어들만 보게 하기)
data_unlist <- Filter(function(x){nchar(x)>=2}, data_unlist)
wordcount <- table(data_unlist)
wordcount_top <-head(sort(wordcount, decreasing = T),100)
wordcount_top
#영화 "박열" 리뷰임을 이미 알고 있는데 영화와 박열이라는 단어가 많으므로 제외시킨다.
data_unlist <- gsub("영화", "", data_unlist)
data_unlist <- gsub("박열", "", data_unlist)
#특수문자 삭제
data_unlist<- gsub('[~!@#$%&*()_+=?<>]','',data_unlist)
data_unlist <- gsub("\\[","",data_unlist)
#자음 삭제(ㅋㅋ,ㅎㅎ,ㅇㅇ 등)
data_unlist <- gsub('[ㄱ-ㅎ]','',data_unlist)
#ㅜㅜ나 ㅠㅠ 등 삭제
data_unlist<- gsub('(ㅜ|ㅠ)','',data_unlist)
#숫자 삭제
data_unlist <- gsub("\\d+","",data_unlist)
